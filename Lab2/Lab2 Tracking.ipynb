{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c8f5811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary imports for the lab\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import IPython.display\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a53510c",
   "metadata": {},
   "source": [
    "# 1. Object Localization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd9a304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture(\"original.mov\")\n",
    "\n",
    "while True:\n",
    "    success, frame = video.read()\n",
    "    \n",
    "    if success:\n",
    "        frame = cv2.resize(frame, (368, 640))\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) \n",
    "        \n",
    "        _, th1 = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "        contours, _ = cv2.findContours(th1, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "        \n",
    "        if not contours:\n",
    "            cv2.imshow('Object Localization', frame)\n",
    "        else:\n",
    "            img = frame.copy()\n",
    "            min_area_threshold = 50\n",
    "            for contour in contours:\n",
    "                area = cv2.contourArea(contour)\n",
    "                if area > min_area_threshold:\n",
    "                    x, y, w, h = cv2.boundingRect(contour)\n",
    "                    cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 3)        \n",
    "\n",
    "            cv2.imshow('Object Localization', img)\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "        \n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1d7b51",
   "metadata": {},
   "source": [
    "# 2. Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c16c9665",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: (357, 5)}\n",
      "{0: (355, 4), 1: (240, 3)}\n",
      "{0: (355, 4), 1: (237, 8)}\n",
      "{0: (355, 6), 1: (237, 8)}\n",
      "{0: (355, 6), 1: (236, 14)}\n",
      "{0: (348, 7), 1: (236, 14)}\n",
      "{0: (348, 7), 1: (235, 19)}\n",
      "{0: (348, 7), 1: (235, 19)}\n",
      "{0: (348, 7), 1: (229, 25)}\n",
      "{0: (343, 7), 1: (229, 25)}\n",
      "{0: (343, 7), 1: (226, 31)}\n",
      "{0: (343, 7), 1: (225, 43)}\n",
      "{0: (347, 6), 1: (225, 43)}\n",
      "{1: (226, 56), 0: (347, 6)}\n",
      "{1: (226, 56), 0: (348, 5)}\n",
      "{1: (228, 68), 0: (348, 5)}\n",
      "{1: (228, 68), 0: (353, 5)}\n",
      "{1: (230, 81), 0: (353, 5)}\n",
      "{1: (230, 81), 0: (357, 4)}\n",
      "{1: (232, 94), 0: (357, 4)}\n",
      "{1: (235, 107)}\n",
      "{1: (236, 120)}\n",
      "{1: (238, 132)}\n",
      "{1: (240, 145)}\n",
      "{1: (242, 157)}\n",
      "{1: (244, 170)}\n",
      "{1: (246, 182)}\n",
      "{1: (248, 195)}\n",
      "{1: (250, 206)}\n",
      "{1: (251, 219)}\n",
      "{1: (253, 230)}\n",
      "{1: (256, 241)}\n",
      "{1: (257, 253)}\n",
      "{1: (259, 266)}\n",
      "{1: (262, 278)}\n",
      "{1: (264, 288)}\n",
      "{1: (266, 297)}\n",
      "{1: (266, 307)}\n",
      "{1: (264, 319)}\n",
      "{1: (265, 330)}\n",
      "{1: (267, 342)}\n",
      "{1: (272, 352)}\n",
      "{1: (278, 361)}\n",
      "{1: (281, 370)}\n",
      "{1: (285, 379)}\n",
      "{1: (286, 388)}\n",
      "{1: (286, 396)}\n",
      "{1: (289, 404)}\n",
      "{1: (293, 412)}\n",
      "{1: (295, 419)}\n",
      "{1: (297, 427)}\n",
      "{1: (303, 448)}\n",
      "{1: (299, 428)}\n",
      "{1: (301, 435)}\n",
      "{1: (304, 444)}\n",
      "{1: (306, 452)}\n",
      "{1: (308, 460)}\n",
      "{1: (312, 467)}\n",
      "{1: (319, 475)}\n",
      "{1: (320, 485)}\n",
      "{2: (326, 500)}\n",
      "{2: (324, 510)}\n",
      "{2: (321, 522)}\n",
      "{2: (333, 518)}\n",
      "{2: (331, 530)}\n",
      "{2: (339, 537)}\n",
      "{3: (354, 4)}\n",
      "{3: (351, 4)}\n",
      "{3: (351, 5)}\n",
      "{3: (347, 5)}\n",
      "{3: (347, 6)}\n",
      "{3: (345, 6)}\n",
      "{3: (345, 7)}\n",
      "{3: (344, 7)}\n",
      "{3: (344, 7)}\n",
      "{3: (344, 7)}\n",
      "{3: (345, 7)}\n",
      "{3: (345, 6)}\n",
      "{3: (345, 7)}\n",
      "{3: (345, 7)}\n",
      "{3: (345, 7)}\n",
      "{3: (346, 7)}\n",
      "{3: (346, 7)}\n",
      "{3: (346, 7)}\n",
      "{3: (345, 7)}\n",
      "{3: (344, 7)}\n",
      "{3: (344, 7)}\n",
      "{3: (342, 8)}\n",
      "{3: (342, 8)}\n",
      "{3: (341, 8)}\n",
      "{3: (341, 8)}\n",
      "{3: (341, 8)}\n",
      "{3: (341, 8)}\n",
      "{3: (341, 7)}\n",
      "{3: (345, 6)}\n",
      "{3: (341, 6)}\n",
      "{3: (345, 5)}\n",
      "{3: (351, 5)}\n",
      "{3: (352, 4)}\n",
      "{3: (352, 3)}\n"
     ]
    }
   ],
   "source": [
    "from tracker import *\n",
    "tracker = EuclideanDistTracker()\n",
    "video = cv2.VideoCapture(\"original.mov\")\n",
    "detections = []\n",
    "\n",
    "while True:\n",
    "    success, frame = video.read()\n",
    "\n",
    "    if success:\n",
    "        frame = cv2.resize(frame, (368, 640))\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        _, th1 = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "        contours, _ = cv2.findContours(th1, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "        if not contours:\n",
    "            cv2.imshow('Object Tracking', frame)\n",
    "        else:\n",
    "            img = frame.copy()\n",
    "            min_area_threshold = 50\n",
    "            for contour in contours:\n",
    "                area = cv2.contourArea(contour)\n",
    "                if area > min_area_threshold:\n",
    "                    x, y, w, h = cv2.boundingRect(contour)\n",
    "                    detections.append((x, y, w, h))\n",
    "                    \n",
    "            # Update tracker with the detections\n",
    "            boxes_ids = tracker.update(detections)\n",
    "\n",
    "            # Visualize bounding boxes and IDs\n",
    "            for box_id in boxes_ids:\n",
    "                x, y, w, h, id = box_id\n",
    "                cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 3)\n",
    "                cv2.putText(img, str(id), (x, y + 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "            cv2.imshow('Object Tracking', img)\n",
    "            detections = []  # Reset detections for the next frame\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4938ce0f",
   "metadata": {},
   "source": [
    "# Feature-Based tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4acde2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def track(file_path, fps):\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "\n",
    "\n",
    "    # Parameters for Shi-Tomasi corner detection and Lucas-Kanade Optical Flow\n",
    "    parameters_shitomasi = dict(maxCorners=100, qualityLevel=0.3, minDistance=10)\n",
    "    parameter_lucas_kanade = dict(winSize=(15, 15), maxLevel=2, criteria=(cv2.TERM_CRITERIA_EPS |\n",
    "                                                                          cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "    colours = np.random.randint(0, 255, size=(100, 3))\n",
    "\n",
    "    # Read the first frame and convert to grayscale\n",
    "    ok, frame = cap.read()\n",
    "    if not ok:\n",
    "        print(\"[ERROR] cannot get frame from video\")\n",
    "        sys.exit()\n",
    "    frame_gray_init = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect corners using Shi-Tomasi in the initial frame\n",
    "    edges = cv2.goodFeaturesToTrack(frame_gray_init, mask=None, **parameters_shitomasi)\n",
    "\n",
    "    canvas = np.zeros_like(frame)\n",
    "\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            print(\"[INFO] end of file reached\")\n",
    "            break\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Calculate optical flow using Lucas-Kanade\n",
    "        update_edges, status, errors = cv2.calcOpticalFlowPyrLK(frame_gray_init, frame_gray, edges, None,\n",
    "                                                                **parameter_lucas_kanade)\n",
    "        new_edges = update_edges[status == 1]\n",
    "        old_edges = edges[status == 1]\n",
    "\n",
    "        for i, (new, old) in enumerate(zip(new_edges, old_edges)):\n",
    "            a, b = new.ravel()\n",
    "            c, d = old.ravel()\n",
    "\n",
    "            # Draw lines between old and new corner points with random colour\n",
    "            mask = cv2.line(canvas, (int(a), int(b)), (int(c), int(d)), colours[i].tolist(), 2)\n",
    "            # Draw circle around new position\n",
    "            frame = cv2.circle(frame, (int(a), int(b)), 5, colours[i].tolist(), -1)\n",
    "\n",
    "        result = cv2.add(frame, mask)\n",
    "        cv2.imshow('Optical Flow (sparse)', result)\n",
    "        if cv2.waitKey(fps) & 0xFF == ord('q'):\n",
    "            break\n",
    "        frame_gray_init = frame_gray.copy()\n",
    "        edges = new_edges.reshape(-1, 1, 2)\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ca6ff5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "track(\"Easy.mp4\", 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e001d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] end of file reached\n"
     ]
    }
   ],
   "source": [
    "track(\"original.mov\", 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9b1e00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
